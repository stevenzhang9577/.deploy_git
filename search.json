[{"title":"对抗相关思考","path":"/2023/11/01/adversarial-test/","content":"对抗相关思考自动驾驶中汽研相关一个对交通信号灯（国内不同样式）感兴趣，一个对围绕着一辆车不断做 query 感兴趣; 通过视频暗箱和摄像头的方式进行攻击 自动驾驶训练阶段会用到强化学习 (我们能做吗)? 在强化学习的训练阶段，我们可以用到 wtr: 国内车厂自动驾驶模型训练流程？ ACM Computing Survey 综述相关标题写：Challenges and Future Directions? 论文总结 RPN brings with redundant region proposals and smaller feature maps of Region of Interest (RoI), which may neutralize adversarial perturbations and lead to more challenges for adversarial attack on two-stage detectors.Paper : To Make Yourself Invisible with Adversarial Semantic Contours 2023Summary: RPN 可以抵消对抗扰动 Some studies reveal that it’s more difficult to conduct adversarial attacks on Vision Transformers (ViT), because they learn more generalized contextual informationPaper: On the adversarial robustness of visual transformers 2021Summary: ViT 更难被攻击，因为他们学到了更多的通用上下文信息。 It’s equally worthy as global attack to be studied in both algorithms and applications, because it’s a typical NP-hard problem and its setting is closer to that in real-world attack, where only limited area of the environment can be disturbedPaper: To Make Yourself Invisible with Adversarial Semantic Contours 2023Summary: Sparse attack 非常重要，因为该方法更贴近现实攻击，因为它只有限制性的区域可以被修改。 the authors thoroughly analyze the question “What is an object?”, and point out that an object should have closed boundaries and a different appearance against the background; three distinctive characteristics of objects are investigated, including “a closed boundary in space”, “a different appearance” and “salience against the background”Paper: What is an object? 2010Summary: 如果想要在目标检测任务上表现较好的话，物体应该有清晰且封闭的轮廓，并在背景下有不同的外观。 Detection Transformer (DETR) (Carion et al., 2020) applies Transformer (Vaswani et al., 2017) architecture and removes postprocessing operations such as NMSPaper: End-to-End Object Detection with Transformers 2020Summary: DETR 相较于之前的目标检测模型，移除了预处理步骤 - e.g. NMS It has been studied that ViT models have global receptive fields, which allows to model global context and therefore lead to robustness of learned features (Naseer et al., 2021).Paper : Intriguing Properties of Vision Transformers 2021Summary: ViT 具有 global receptive fields, 导致模型可以学到 global context, 使得学到的特征更鲁棒 with Swin-T as the backbone network, the adversarial robustness of Mask R-CNN is improved compared to that with ResNet50. Swin-T have larger receptive fields (window size of at least 7 × 7) than ResNet50 (kernel size of 3 × 3) (Liu et al., 2022b) and results in better robustness.Paper: A convnet for the 2020s 2022Summary: Swin-T 具有更大的 receptive field, 导致模型更鲁棒。 among the three Detection Transformers, the two incremental versions of DETR appear to be much easier to be attacked, which suggests their improvement measures to uplift the prediction accuracy in terms of mean Average Precision (mAP) bring with worse adversarial robustness. One typical difference between DETR and its incremental versions is that DETR uses Cross Entropy Loss while the other two models use Focal Loss (Lin et al., 2017). This lead to better predicting performance but sacrifice the robustness, maybe because Focal Loss is proposed based on Binary Cross Entropy Loss to address the imbalance of positive and negative samples, and to put more weights on objects that are harder to distinguish.Paper : To Make Yourself Invisible with Adversarial Semantic Contours 2023Summary: DETR 比他的两个变种更鲁棒，这是由于 DETR 使用的是 Cross Entropy Loss, 而他的变种使用的是 Focal Loss, 可能得原因是 Focal Loss 是为了解决正负样本的不平衡现象，因此导致目标上有更大的权重以至于更难去区分。 Despite adopting diverse architectures and parameters, source and target models often share similar decision boundaries.Paper: A New Ensemble Adversarial Attack Powered by Long-Term Gradient Memories 2020Summary: 尽管模型的架构和参数都不相同，他们通常有相似的决策边界。 Crafting an adversarial example is analogous to training a model, and the transferability of the adversarial example is analogous to the generalizability of the modelPaper: Boosting adversarial attacks with momentum 2018Summary: 生成一个对抗样本的过程与训练一个模型类似，因此对抗样本的迁移性与模型的泛化性类似。 Compared to the magnitude of the perturbation, the spatial structure of the adversarial perturbation has stronger impact on the final fooling ability (Xie et al. 2017)Paper: Adversarial examples for semantic segmentation and object detection. 2017Summary: 与扰动的大小相比，对抗性扰动的 空间结构 对最终的攻击能力有更大的影响。 One caveat of additive noise attack is the lack of balance between being visually plausible and imperceptible while having high attack success ratePaper: Watch out! Motion is Blurring Blurring the Vision of Your Deep Neural Networks 2020Summary: 对图像添加噪声的攻击方法可能会导致不能很好的平衡视觉的真实性和不可见性。 Paper:Summary: Paper:Summary: Paper:Summary: Paper:Summary: Paper:Summary: Paper:Summary: Paper:Summary: Paper:Summary: Paper:Summary: Paper:Summary: Paper:Summary: Paper:Summary: Paper:Summary: Paper:Summary: Paper:Summary:"}]